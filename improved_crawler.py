#!/usr/bin/env python3
"""
æ”¹é€²ç‰ˆå°ç£è‚¡ç¥¨çˆ¬èŸ²
åŒ…å«å®Œå–„çš„é€Ÿç‡é™åˆ¶è™•ç†ã€é‡è©¦æ©Ÿåˆ¶ã€é›¢ç·šæ¨¡å¼
å°ˆé–€æŠ“å– ROEã€EPSã€å¹´ç‡Ÿæ”¶æˆé•·ç‡ã€æœˆç‡Ÿæ”¶æˆé•·ç‡ç­‰é—œéµæŒ‡æ¨™
"""

import pandas as pd
import time
from datetime import datetime, timedelta
import os
import random
import requests
import yfinance as yf
import numpy as np
from functools import wraps

class ImprovedStockCrawler:
    def __init__(self):
        # æ›´ä¿å®ˆçš„è«‹æ±‚è¨­å®š
        self.batch_size = 3  # æ¯æ‰¹åªè™•ç†3æ”¯è‚¡ç¥¨
        self.sleep_time = 30  # æ‰¹æ¬¡ä¹‹é–“ç­‰å¾…30ç§’
        self.request_delay = 10  # è«‹æ±‚ä¹‹é–“ç­‰å¾…10ç§’
        self.max_retries = 3
        self.retry_base_delay = 60  # åŸºç¤é‡è©¦å»¶é²60ç§’
        
        # è³‡æ–™å¤¾è¨­å®š
        self.data_dir = 'data'
        self.raw_dir = os.path.join(self.data_dir, 'raw')
        self.processed_dir = os.path.join(self.data_dir, 'processed')
        self.logs_dir = os.path.join(self.data_dir, 'logs')
        
        for directory in [self.data_dir, self.raw_dir, self.processed_dir, self.logs_dir]:
            os.makedirs(directory, exist_ok=True)
        
        # æª”æ¡ˆè·¯å¾‘
        self.taiwan_stocks_file = os.path.join(self.raw_dir, 'taiwan_stocks_list.txt')
        self.cache_file = os.path.join(self.raw_dir, 'stock_cache.csv')
        self.interim_file = os.path.join(self.raw_dir, f'interim_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv')
        self.final_file = os.path.join(self.processed_dir, f'stock_data_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv')
        self.log_file = os.path.join(self.logs_dir, f'improved_crawler_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
        
        # å°ç£ä¸»è¦è‚¡ç¥¨æ¸…å–®ï¼ˆç²¾é¸ç‰ˆæœ¬ï¼‰
        self.taiwan_stocks = [
            # ç§‘æŠ€è‚¡ - æœ€é‡è¦çš„å¹¾æ”¯
            ('2330', 'å°ç©é›»'), ('2454', 'è¯ç™¼ç§‘'), ('2317', 'é´»æµ·'),
            ('3711', 'æ—¥æœˆå…‰æŠ•æ§'), ('2303', 'è¯é›»'),
            
            # é‡‘èè‚¡
            ('2891', 'ä¸­ä¿¡é‡‘'), ('2882', 'åœ‹æ³°é‡‘'), ('2881', 'å¯Œé‚¦é‡‘'),
            ('2886', 'å…†è±é‡‘'), ('2884', 'ç‰å±±é‡‘'),
            
            # å‚³çµ±ç”¢æ¥­
            ('2002', 'ä¸­é‹¼'), ('1301', 'å°å¡‘'), ('1303', 'å—äº'),
            ('2105', 'æ­£æ–°'), ('1216', 'çµ±ä¸€'),
            
            # é›»å­è‚¡
            ('2382', 'å»£é”'), ('2357', 'è¯ç¢©'), ('2308', 'å°é”é›»'),
            ('2327', 'åœ‹å·¨'), ('2379', 'ç‘æ˜±'),
            
            # å…¶ä»–é‡è¦è‚¡ç¥¨
            ('2412', 'ä¸­è¯é›»'), ('2912', 'çµ±ä¸€è¶…'), ('2207', 'å’Œæ³°è»Š'),
            ('3008', 'å¤§ç«‹å…‰'), ('2395', 'ç ”è¯')
        ]
        
        # åˆå§‹åŒ–
        self.initialize_stock_list()
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
    
    def log_message(self, message):
        """è¨˜éŒ„æ—¥èªŒ"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_entry = f"[{timestamp}] {message}"
        print(log_entry)
        
        try:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                f.write(log_entry + '\n')
        except:
            pass
    
    def initialize_stock_list(self):
        """åˆå§‹åŒ–è‚¡ç¥¨æ¸…å–®"""
        if not os.path.exists(self.taiwan_stocks_file):
            with open(self.taiwan_stocks_file, 'w', encoding='utf-8') as f:
                for code, name in self.taiwan_stocks:
                    f.write(f"{code}.TW,{name}\n")
            self.log_message(f"å·²ç”Ÿæˆå°ç£è‚¡ç¥¨æ¸…å–®: {len(self.taiwan_stocks)} æ”¯è‚¡ç¥¨")
        else:
            self.log_message(f"ä½¿ç”¨ç¾æœ‰çš„å°ç£è‚¡ç¥¨æ¸…å–®")
    
    def rate_limit_handler(func):
        """é€Ÿç‡é™åˆ¶è™•ç†è£é£¾å™¨"""
        @wraps(func)
        def wrapper(self, *args, **kwargs):
            for attempt in range(self.max_retries):
                try:
                    result = func(self, *args, **kwargs)
                    return result
                except Exception as e:
                    error_str = str(e).lower()
                    if 'rate limit' in error_str or 'too many requests' in error_str:
                        wait_time = self.retry_base_delay * (2 ** attempt)  # æŒ‡æ•¸é€€é¿
                        self.log_message(f"é‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’... (å˜—è©¦ {attempt + 1}/{self.max_retries})")
                        time.sleep(wait_time)
                        if attempt == self.max_retries - 1:
                            self.log_message("å·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œè·³éæ­¤è«‹æ±‚")
                            return None
                    else:
                        self.log_message(f"å…¶ä»–éŒ¯èª¤: {str(e)}")
                        return None
            return None
        return wrapper
    
    @rate_limit_handler
    def get_stock_data_safe(self, stock_code):
        """å®‰å…¨åœ°ç²å–è‚¡ç¥¨æ•¸æ“š"""
        stock = yf.Ticker(stock_code)
        info = stock.info
        
        if not info or len(info) < 5:  # åŸºæœ¬æª¢æŸ¥
            return None
        
        # ç²å–åŸºæœ¬æŒ‡æ¨™
        roe = info.get('returnOnEquity', 0)
        if roe and not np.isnan(roe):
            roe = roe * 100
        else:
            roe = 0
        
        eps = info.get('trailingEps', 0)
        if eps and np.isnan(eps):
            eps = 0
        
        # ç°¡åŒ–ç‰ˆç‡Ÿæ”¶æˆé•·ç‡è¨ˆç®—
        annual_growth = 0
        quarterly_growth = 0
        
        try:
            # å˜—è©¦ç²å–å¹´åº¦æ•¸æ“š
            financials = stock.financials
            if financials is not None and not financials.empty and len(financials.columns) >= 2:
                revenue_keys = ['Total Revenue', 'Revenue']
                for key in revenue_keys:
                    if key in financials.index:
                        revenue_data = financials.loc[key]
                        if len(revenue_data) >= 2:
                            current = revenue_data.iloc[0]
                            previous = revenue_data.iloc[1]
                            if previous and previous != 0:
                                annual_growth = ((current - previous) / previous) * 100
                        break
        except:
            pass
        
        try:
            # å˜—è©¦ç²å–å­£åº¦æ•¸æ“š
            quarterly = stock.quarterly_financials
            if quarterly is not None and not quarterly.empty and len(quarterly.columns) >= 4:
                revenue_keys = ['Total Revenue', 'Revenue']
                for key in revenue_keys:
                    if key in quarterly.index:
                        revenue_data = quarterly.loc[key]
                        if len(revenue_data) >= 4:
                            current_q = revenue_data.iloc[0]
                            year_ago_q = revenue_data.iloc[3]
                            if year_ago_q and year_ago_q != 0:
                                quarterly_growth = ((current_q - year_ago_q) / year_ago_q) * 100
                        break
        except:
            pass
        
        return {
            'stock_code': stock_code,
            'name': info.get('longName', info.get('shortName', '')),
            'ROE': round(roe, 2),
            'EPS': round(eps, 2),
            'å¹´ç‡Ÿæ”¶æˆé•·ç‡': round(annual_growth, 2),
            'æœˆç‡Ÿæ”¶æˆé•·ç‡': round(quarterly_growth, 2),
            'market_cap': info.get('marketCap', 0),
            'sector': info.get('sector', ''),
            'industry': info.get('industry', '')
        }
    
    def load_cached_data(self):
        """è¼‰å…¥å¿«å–æ•¸æ“š"""
        if os.path.exists(self.cache_file):
            try:
                df = pd.read_csv(self.cache_file)
                self.log_message(f"è¼‰å…¥å¿«å–æ•¸æ“š: {len(df)} æ”¯è‚¡ç¥¨")
                return df
            except:
                pass
        return pd.DataFrame()
    
    def save_to_cache(self, data):
        """ä¿å­˜åˆ°å¿«å–"""
        try:
            df = pd.DataFrame(data)
            df.to_csv(self.cache_file, index=False, encoding='utf-8-sig')
            self.log_message(f"å·²ä¿å­˜åˆ°å¿«å–: {len(data)} ç­†æ•¸æ“š")
        except Exception as e:
            self.log_message(f"å¿«å–ä¿å­˜å¤±æ•—: {str(e)}")
    
    def crawl_stocks_conservative(self):
        """ä¿å®ˆæ¨¡å¼çˆ¬å–è‚¡ç¥¨æ•¸æ“š"""
        self.log_message("ğŸš€ é–‹å§‹ä¿å®ˆæ¨¡å¼çˆ¬å–å°ç£è‚¡ç¥¨æ•¸æ“š...")
        self.log_message("âš ï¸ ä½¿ç”¨ä¿å®ˆè¨­å®šä»¥é¿å…é€Ÿç‡é™åˆ¶")
        
        # è¼‰å…¥å¿«å–æ•¸æ“š
        cached_df = self.load_cached_data()
        cached_codes = set(cached_df['stock_code'].tolist()) if not cached_df.empty else set()
        
        # è®€å–è‚¡ç¥¨æ¸…å–®
        stocks_to_process = []
        with open(self.taiwan_stocks_file, 'r', encoding='utf-8') as f:
            for line in f:
                if ',' in line:
                    parts = line.strip().split(',')
                    stock_code = parts[0]
                    stock_name = parts[1] if len(parts) > 1 else ''
                    
                    # è·³éå·²å¿«å–çš„è‚¡ç¥¨
                    if stock_code not in cached_codes:
                        stocks_to_process.append((stock_code, stock_name))
        
        self.log_message(f"ğŸ“‹ éœ€è¦è™•ç†çš„è‚¡ç¥¨: {len(stocks_to_process)} æ”¯")
        self.log_message(f"ğŸ“‹ å·²å¿«å–çš„è‚¡ç¥¨: {len(cached_codes)} æ”¯")
        
        all_results = cached_df.to_dict('records') if not cached_df.empty else []
        successful_count = len(cached_codes)
        
        try:
            # æ‰¹æ¬¡è™•ç†
            for i in range(0, len(stocks_to_process), self.batch_size):
                batch = stocks_to_process[i:i + self.batch_size]
                batch_num = i // self.batch_size + 1
                total_batches = (len(stocks_to_process) + self.batch_size - 1) // self.batch_size
                
                self.log_message(f"\nğŸ“¦ è™•ç†ç¬¬ {batch_num}/{total_batches} æ‰¹")
                
                batch_results = []
                for stock_code, stock_name in batch:
                    self.log_message(f"ğŸ¯ è™•ç† {stock_code} ({stock_name})...")
                    
                    data = self.get_stock_data_safe(stock_code)
                    
                    if data:
                        # ä½¿ç”¨æä¾›çš„ä¸­æ–‡åç¨±
                        if not data['name'] or len(data['name']) < 2:
                            data['name'] = stock_name
                        
                        batch_results.append(data)
                        all_results.append(data)
                        successful_count += 1
                        self.log_message(f"âœ… æˆåŠŸç²å– {stock_code} æ•¸æ“š")
                    else:
                        self.log_message(f"âŒ è·³é {stock_code}")
                    
                    # è«‹æ±‚ä¹‹é–“çš„å»¶é²
                    time.sleep(self.request_delay + random.uniform(2, 5))
                
                # æ¯æ‰¹æ¬¡å¾Œä¿å­˜åˆ°å¿«å–
                if batch_results:
                    self.save_to_cache(all_results)
                
                # æ‰¹æ¬¡ä¹‹é–“çš„ç­‰å¾…
                if i + self.batch_size < len(stocks_to_process):
                    self.log_message(f"â³ ç­‰å¾… {self.sleep_time} ç§’å¾Œè™•ç†ä¸‹ä¸€æ‰¹...")
                    time.sleep(self.sleep_time)
            
            # è™•ç†å®Œæˆ
            if all_results:
                df = pd.DataFrame(all_results)
                
                # æ•¸æ“šæ¸…ç†
                for col in ['ROE', 'EPS', 'å¹´ç‡Ÿæ”¶æˆé•·ç‡', 'æœˆç‡Ÿæ”¶æˆé•·ç‡']:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                
                # ç§»é™¤é‡è¤‡é …
                df = df.drop_duplicates(subset=['stock_code'], keep='last')
                
                # ä¿å­˜æœ€çµ‚çµæœ
                df.to_csv(self.final_file, index=False, encoding='utf-8-sig')
                
                self.generate_report(df)
                self.log_message(f"ğŸ‰ çˆ¬å–å®Œæˆï¼æ•¸æ“šå·²ä¿å­˜åˆ°: {os.path.basename(self.final_file)}")
                
                return True
            else:
                self.log_message("âŒ æ²’æœ‰ç²å–åˆ°ä»»ä½•æ–°æ•¸æ“š")
                return False
                
        except KeyboardInterrupt:
            self.log_message("\nâ¹ï¸ ç¨‹å¼è¢«ä½¿ç”¨è€…ä¸­æ–·")
            if all_results:
                df = pd.DataFrame(all_results)
                df.to_csv(f"interrupted_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv", 
                         index=False, encoding='utf-8-sig')
                self.log_message("ğŸ’¾ å·²ä¿å­˜ä¸­æ–·å‰çš„æ•¸æ“š")
            return False
        except Exception as e:
            self.log_message(f"âŒ çˆ¬å–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return False
    
    def generate_report(self, df):
        """ç”Ÿæˆå ±å‘Š"""
        self.log_message("\nğŸ“Š æ•¸æ“šçµ±è¨ˆå ±å‘Š:")
        self.log_message(f"ç¸½è‚¡ç¥¨æ•¸: {len(df)}")
        
        # çµ±è¨ˆæœ‰æ•ˆæ•¸æ“š
        valid_roe = df[df['ROE'] > 0]
        valid_eps = df[df['EPS'] > 0]
        
        self.log_message(f"æœ‰æ•ˆ ROE æ•¸æ“š: {len(valid_roe)} æ”¯ ({len(valid_roe)/len(df)*100:.1f}%)")
        self.log_message(f"æœ‰æ•ˆ EPS æ•¸æ“š: {len(valid_eps)} æ”¯ ({len(valid_eps)/len(df)*100:.1f}%)")
        
        if len(valid_roe) > 0:
            self.log_message(f"ROE ç¯„åœ: {valid_roe['ROE'].min():.2f}% ~ {valid_roe['ROE'].max():.2f}%")
        if len(valid_eps) > 0:
            self.log_message(f"EPS ç¯„åœ: {valid_eps['EPS'].min():.2f} ~ {valid_eps['EPS'].max():.2f}")
        
        # å„ªè³ªè‚¡ç¥¨
        quality_stocks = df[
            (df['ROE'] > 15) & 
            (df['EPS'] > 0) & 
            (df['å¹´ç‡Ÿæ”¶æˆé•·ç‡'] > 10)
        ]
        
        self.log_message(f"ğŸ† å„ªè³ªè‚¡ç¥¨ (ROE>15%, EPS>0, å¹´æˆé•·>10%): {len(quality_stocks)} æ”¯")
        
        if len(quality_stocks) > 0:
            top3 = quality_stocks.nlargest(3, 'ROE')
            self.log_message("å‰3åå„ªè³ªè‚¡ç¥¨:")
            for _, row in top3.iterrows():
                self.log_message(f"  {row['stock_code']} {row['name']}: ROE={row['ROE']:.2f}%, EPS={row['EPS']:.2f}")
    
    def create_sample_with_real_data(self):
        """ä½¿ç”¨çœŸå¯¦æ•¸æ“šå‰µå»ºç¤ºä¾‹ï¼Œå¦‚æœçˆ¬å–å¤±æ•—å‰‡ä½¿ç”¨å‡æ•¸æ“š"""
        self.log_message("ğŸ¯ å˜—è©¦å‰µå»ºåŒ…å«çœŸå¯¦æ•¸æ“šçš„ç¤ºä¾‹æ–‡ä»¶...")
        
        # é¦–å…ˆå˜—è©¦çˆ¬å–å¹¾æ”¯ä¸»è¦è‚¡ç¥¨
        sample_stocks = [
            ('2330.TW', 'å°ç©é›»'),
            ('2317.TW', 'é´»æµ·'),
            ('2891.TW', 'ä¸­ä¿¡é‡‘')
        ]
        
        real_data = []
        for stock_code, stock_name in sample_stocks:
            self.log_message(f"å˜—è©¦ç²å– {stock_code} çš„çœŸå¯¦æ•¸æ“š...")
            data = self.get_stock_data_safe(stock_code)
            
            if data:
                data['name'] = stock_name
                real_data.append(data)
                self.log_message(f"âœ… æˆåŠŸç²å– {stock_code} çœŸå¯¦æ•¸æ“š")
                time.sleep(15)  # é•·æ™‚é–“ç­‰å¾…é¿å…é™åˆ¶
            else:
                self.log_message(f"âŒ ç„¡æ³•ç²å– {stock_code} çœŸå¯¦æ•¸æ“š")
            
            if len(real_data) >= 2:  # åªè¦ç²å–åˆ°2æ”¯å°±è¶³å¤ 
                break
        
        # å¦‚æœæœ‰çœŸå¯¦æ•¸æ“šï¼Œèˆ‡å‡æ•¸æ“šçµåˆ
        if real_data:
            self.log_message(f"âœ… ç²å¾— {len(real_data)} æ”¯çœŸå¯¦æ•¸æ“š")
            
            # è£œå……ä¸€äº›å‡æ•¸æ“š
            fake_data = self.generate_fake_data(count=len(self.taiwan_stocks) - len(real_data))
            all_data = real_data + fake_data
        else:
            self.log_message("âš ï¸ ç„¡æ³•ç²å–çœŸå¯¦æ•¸æ“šï¼Œä½¿ç”¨ç´”å‡æ•¸æ“š")
            all_data = self.generate_fake_data(count=len(self.taiwan_stocks))
        
        # ä¿å­˜æ··åˆæ•¸æ“š
        df = pd.DataFrame(all_data)
        hybrid_file = os.path.join(self.processed_dir, f'hybrid_stock_data_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv')
        df.to_csv(hybrid_file, index=False, encoding='utf-8-sig')
        
        self.log_message(f"ğŸ‰ æ··åˆæ•¸æ“šæ–‡ä»¶å·²å‰µå»º: {os.path.basename(hybrid_file)}")
        self.generate_report(df)
        
        return hybrid_file
    
    def generate_fake_data(self, count):
        """ç”Ÿæˆå‡æ•¸æ“š"""
        fake_data = []
        np.random.seed(42)
        
        for i, (code, name) in enumerate(self.taiwan_stocks[:count]):
            fake_data.append({
                'stock_code': f"{code}.TW",
                'name': name,
                'ROE': round(np.random.normal(15, 8), 2),
                'EPS': round(np.random.normal(2, 1.5), 2),
                'å¹´ç‡Ÿæ”¶æˆé•·ç‡': round(np.random.normal(10, 20), 2),
                'æœˆç‡Ÿæ”¶æˆé•·ç‡': round(np.random.normal(8, 25), 2),
                'market_cap': int(np.random.uniform(1e9, 1e12)),
                'sector': 'Technology',
                'industry': 'Semiconductors'
            })
        
        return fake_data

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ”§ æ”¹é€²ç‰ˆå°ç£è‚¡ç¥¨çˆ¬èŸ²")
    print("=" * 50)
    
    crawler = ImprovedStockCrawler()
    
    print("\nè«‹é¸æ“‡åŸ·è¡Œæ¨¡å¼:")
    print("1. ä¿å®ˆæ¨¡å¼çˆ¬å– (æ¨è–¦)")
    print("2. å‰µå»ºæ··åˆæ•¸æ“š (çœŸå¯¦+å‡æ•¸æ“š)")
    print("3. åƒ…ä½¿ç”¨å‡æ•¸æ“š")
    
    try:
        choice = input("\nè«‹è¼¸å…¥é¸é … (1-3): ").strip()
        
        if choice == '1':
            crawler.crawl_stocks_conservative()
            
        elif choice == '2':
            crawler.create_sample_with_real_data()
            
        elif choice == '3':
            fake_data = crawler.generate_fake_data(len(crawler.taiwan_stocks))
            df = pd.DataFrame(fake_data)
            fake_file = os.path.join(crawler.processed_dir, f'fake_stock_data_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv')
            df.to_csv(fake_file, index=False, encoding='utf-8-sig')
            print(f"å‡æ•¸æ“šæ–‡ä»¶å·²å‰µå»º: {os.path.basename(fake_file)}")
            crawler.generate_report(df)
            
        else:
            print("ç„¡æ•ˆé¸é …")
            
    except KeyboardInterrupt:
        print("\nç¨‹å¼è¢«ä¸­æ–·")
    except Exception as e:
        print(f"åŸ·è¡ŒéŒ¯èª¤: {str(e)}")

if __name__ == "__main__":
    main() 